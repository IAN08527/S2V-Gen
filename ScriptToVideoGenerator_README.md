
# ğŸ¬ Script to Video Generator using GenAI

A full-stack web application that transforms written scripts into narrated, visually-rich short videos using open-source GenAI tools. Users can input blogs, stories, or paragraphs, and the app will convert the text into a video with scene-wise narration, stock visuals, and optional subtitles â€” all generated and assembled automatically.

---

## ğŸš€ Features

- ğŸ“ **Script Input**: Accepts long-form text or short articles.
- ğŸ§  **Scene Breakdown**: Splits text into logical scenes using NLP.
- ğŸ” **Keyword Extraction**: Extracts keywords from each scene to find visuals.
- ğŸ–¼ï¸ **Visual Search**: Fetches relevant stock images or videos via Pexels API.
- ğŸ—£ï¸ **Text-to-Speech**: Generates realistic narration using free TTS tools.
- ğŸ¥ **Video Compilation**: Combines visuals and voiceover into an MP4 video.
- ğŸ“¥ **Downloadable Output**: Final video available for download or preview.
- ğŸŒ **Deployed using Free Tools**: Entire stack uses only free and open APIs and libraries.

---

## ğŸ§° Tech Stack

### âš™ï¸ Full-Stack Framework
- [Next.js](https://nextjs.org/) â€“ Used for both frontend and backend (API routes)

### ğŸ§  GenAI & Processing (Free Only)
| Task                    | Tool / Library                |
|-------------------------|-------------------------------|
| Text Segmentation       | Hugging Face Transformers (`T5`, `BART`, etc.) |
| Keyword Extraction      | `RAKE`, `YAKE`, or `KeyBERT`  |
| Text-to-Speech          | `gTTS` (Google TTS) or `Coqui TTS` |
| Media Search            | Pexels API (free stock images/videos) |
| Video Composition       | `moviepy` (Python) or `ffmpeg.wasm` (JS) |
| Subtitles (Optional)    | WebVTT or hardcoded via moviepy |

---

## ğŸ“‚ Folder Structure

```
/script-to-video-generator
â”‚
â”œâ”€â”€ /pages
â”‚   â”œâ”€â”€ index.js            # Home UI with script input form
â”‚   â””â”€â”€ /api
â”‚       â””â”€â”€ generate.js     # Main API route to handle generation
â”‚
â”œâ”€â”€ /components             # React UI components
â”œâ”€â”€ /lib                    # Utility functions (e.g. extractKeywords.js, tts.js)
â”œâ”€â”€ /styles                 # Tailwind or CSS modules
â”œâ”€â”€ /utils                  # Pexels wrapper, scene splitter logic
â””â”€â”€ /public                 # Static assets (logo, loading animation)
```

---

## ğŸ“¦ Project Workflow

```
1. User enters script on the frontend
2. Backend (Next.js API route) processes:
    a. Segment script into scenes (Hugging Face / custom logic)
    b. Extract keywords per scene
    c. Search Pexels API for images/videos
    d. Generate voiceover using gTTS or Coqui
    e. Assemble audio + visuals using moviepy or ffmpeg
3. Final MP4 video returned for download
```

---

## â˜ï¸ Deployment Plan

| Layer       | Platform         |
|-------------|------------------|
| Frontend    | [Vercel](https://vercel.com/) |
| Backend     | [Render](https://render.com/) / [Railway](https://railway.app/) |
| Media Store | Local/Temp (during processing) |
| Optional DB | Supabase / Firebase (for user history or analytics) |

---

## âš ï¸ Notes & Limitations

- Hugging Face Inference API is **rate-limited**; local model loading is recommended for heavy use.
- TTS can be done locally to avoid usage limits.
- FFmpeg requires server-side processing â€” will need a backend (e.g., Flask on Render) or use [`ffmpeg.wasm`](https://github.com/ffmpegwasm/ffmpeg.wasm) for browser-based compilation.

---

## ğŸŒ± Future Enhancements

- ğŸ¤ User voice input as custom narration
- ğŸŒ Multilingual support (Hindi, Spanish, etc.)
- ğŸ§  Mood-aware visuals (sentiment-based image retrieval)
- ğŸ“¹ Direct upload to YouTube Shorts / Reels format
- ğŸ¨ Add branding overlays or music tracks

---

## ğŸ‘¥ Contributors

- Ian Nilesh Lopes (Project Lead)
- [Your Teammatesâ€™ Names Here]

---

## ğŸ“œ License

This project is open-source and free to use under the MIT License.

---

## ğŸ’¬ Contact / Demo Request

Want a demo or technical breakdown? Contact us at [Your Email or GitHub].
